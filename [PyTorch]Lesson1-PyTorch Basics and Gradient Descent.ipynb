{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 1 - 01. pytorch-basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "torch.float32\n",
      "tensor([1., 2.])\n",
      "torch.float32\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "# How do you create a PyTorch tensor? Illustrate with examples.\n",
    "\n",
    "# one-dimensional tensor (number)\n",
    "t1 = torch.tensor(1.)\n",
    "print(t1)\n",
    "print(t1.dtype)\n",
    "\n",
    "# two-dimensional tensor (matrix)\n",
    "t2 = torch.tensor([1., 2])\n",
    "print(t2)\n",
    "print(t2.dtype)\n",
    "\n",
    "# three-dimentional tensor\n",
    "t3 = torch.tensor([[1., 2], [3, 4]])\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 2., 3.],\n",
      "         [2., 3., 4.]],\n",
      "\n",
      "        [[4., 5., 6.],\n",
      "         [6., 7., 8.]]])\n",
      "torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# How do you inspect the number of dimensions of a tensor and the length along each dimension?\n",
    "\n",
    "# from outer most bracket to inner brackets, one only needs to count the number of elements\n",
    "\n",
    "t4 = torch.tensor([[[1., 2, 3], [2, 3, 4]], [[4, 5, 6], [6, 7, 8]]])\n",
    "print(t4)\n",
    "\n",
    "# the .shape attributes will give the size: 2, 2, 3\n",
    "print(t4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tensor(3.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# What happens if you specify requires_grad=True while creating a tensor? Illustrate with an example.\n",
    "# What is autograd in PyTorch? How is it useful?\n",
    "# What happens when you invoke the backward method of a tensor?\n",
    "# How do you check the derivates of a result tensor w.r.t. the tensors used to compute its value?\n",
    "\n",
    "# if 'requires_grad=True' is set for x, then we can use 'backward' to get a derivative of a variable defined with x w.r.t. x\n",
    "# what the 'backward' does is called: 'autograd'\n",
    "\n",
    "x = torch.tensor(3.)\n",
    "w = torch.tensor(4., requires_grad=True)\n",
    "b = torch.tensor(5., requires_grad=True)\n",
    "\n",
    "y = w * x + b\n",
    "y.backward()\n",
    "# z = 2 * w * x + b\n",
    "# z.backward()\n",
    "# the .grad accumulates the values; e.g., w.grad = 3 + 6 = 9\n",
    "\n",
    "print(x.grad) # x does not have 'requires_grad=True'\n",
    "print(w.grad) # dy/dw\n",
    "print(b.grad) # dy/db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How do you create a Numpy array?\n",
    "# How do you create a PyTorch tensor using a Numpy array?\n",
    "# How do you create a Numpy array using a PyTorch tensor?\n",
    "# Why is interoperability between PyTorch and Numpy important?\n",
    "# What is the purpose of a library like PyTorch if Numpy already provides data structures and utilities to with multi-dimensional numeric data?\n",
    "\n",
    "x = np.array([[1, 2], [3, 4.]])\n",
    "y = torch.from_numpy(x)\n",
    "z = y.numpy()\n",
    "\n",
    "# the interoperability is necessary because most datasets will be read and preprocessed as Numpy arrays.\n",
    "# autograd : automaticaaly compute gradients, necessary for training deep learning models (SGD)\n",
    "# GPU support : efficient for massive datasets and large models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 1 - 02. linear-regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yield_apple  = w11 * temp + w12 * rainfall + w13 * humidity + b1\n",
    "\n",
    "yield_orange = w21 * temp + w22 * rainfall + w23 * humidity + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 69.,  96.,  70.]])\n",
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "# Input (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43], \n",
    "                   [91, 88, 64], \n",
    "                   [87, 134, 58], \n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70]], dtype='float32')\n",
    "\n",
    "# Targets (apples, oranges)\n",
    "targets = np.array([[56, 70], \n",
    "                    [81, 101], \n",
    "                    [119, 133], \n",
    "                    [22, 37], \n",
    "                    [103, 119]], dtype='float32')\n",
    "\n",
    "# Convert inputs and targets to tensors\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.8432,  0.7313,  0.3656],\n",
      "        [ 0.3596,  1.4202,  0.5982]], requires_grad=True)\n",
      "tensor([ 1.4709, -0.5482], requires_grad=True)\n",
      "tensor([[ -68.3643,  146.5749],\n",
      "        [ -78.5068,  195.4325],\n",
      "        [ -39.6869,  255.7326],\n",
      "        [-141.5627,  119.3308],\n",
      "        [ -29.9120,  202.4713]], grad_fn=<AddBackward0>)\n",
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "# Linear regression model from scratch\n",
    "\n",
    "# Weights and biases\n",
    "w = torch.randn(2, 3, requires_grad=True)\n",
    "b = torch.randn(2, requires_grad=True)\n",
    "print(w)\n",
    "print(b)\n",
    "\n",
    "preds = inputs @ w.t() + b\n",
    "print(preds)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction function\n",
    "def model(x):\n",
    "    return x @ w.t() + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function (MSE)\n",
    "def mse(t1, t2):\n",
    "    diff = t1 - t2\n",
    "    return torch.sum(diff * diff) / diff.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1984.9744, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1434.4601, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Compute gradients\n",
    "loss.backward()\n",
    "\n",
    "# parameters update\n",
    "with torch.no_grad():\n",
    "    w -= w.grad * 1e-5\n",
    "    b -= b.grad * 1e-5\n",
    "\n",
    "# Let's verify that the loss is actually lower\n",
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1062.3262, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# re-initialize the gradients to zero\n",
    "w.grad.zero_()\n",
    "b.grad.zero_()\n",
    "\n",
    "# repeat the parameter update based on gradients\n",
    "loss.backward()\n",
    "with torch.no_grad():\n",
    "    w -= w.grad * 1e-5\n",
    "    b -= b.grad * 1e-5\n",
    "\n",
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(94.7028, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Train for 100 epochs\n",
    "for i in range(100):\n",
    "    preds = model(inputs)\n",
    "    loss = mse(preds, targets)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= w.grad * 1e-5\n",
    "        b -= b.grad * 1e-5\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "\n",
    "# Calculate loss\n",
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 53.4854,  71.1355],\n",
      "        [ 79.4850,  97.0326],\n",
      "        [130.8038, 139.9011],\n",
      "        [ -1.7689,  41.9343],\n",
      "        [110.8119, 109.8299]], grad_fn=<AddBackward0>)\n",
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "print(preds)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression using PyTorch built-ins\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "# Input (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43], \n",
    "                   [91, 88, 64], \n",
    "                   [87, 134, 58], \n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70], \n",
    "                   [74, 66, 43], \n",
    "                   [91, 87, 65], \n",
    "                   [88, 134, 59], \n",
    "                   [101, 44, 37], \n",
    "                   [68, 96, 71], \n",
    "                   [73, 66, 44], \n",
    "                   [92, 87, 64], \n",
    "                   [87, 135, 57], \n",
    "                   [103, 43, 36], \n",
    "                   [68, 97, 70]], \n",
    "                  dtype='float32')\n",
    "\n",
    "# Targets (apples, oranges)\n",
    "targets = np.array([[56, 70], \n",
    "                    [81, 101], \n",
    "                    [119, 133], \n",
    "                    [22, 37], \n",
    "                    [103, 119],\n",
    "                    [57, 69], \n",
    "                    [80, 102], \n",
    "                    [118, 132], \n",
    "                    [21, 38], \n",
    "                    [104, 118], \n",
    "                    [57, 69], \n",
    "                    [82, 100], \n",
    "                    [118, 134], \n",
    "                    [20, 38], \n",
    "                    [102, 120]], \n",
    "                   dtype='float32')\n",
    "\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Define dataset\n",
    "train_ds = TensorDataset(inputs, targets)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define data loader\n",
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[103.,  43.,  36.],\n",
      "        [ 91.,  87.,  65.],\n",
      "        [101.,  44.,  37.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 87., 135.,  57.]])\n",
      "tensor([[ 20.,  38.],\n",
      "        [ 80., 102.],\n",
      "        [ 21.,  38.],\n",
      "        [ 22.,  37.],\n",
      "        [118., 134.]])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in train_dl:\n",
    "    print(xb)\n",
    "    print(yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13138.7725, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = nn.Linear(3, 2)\n",
    "\n",
    "# Parameters\n",
    "list(model.parameters())\n",
    "\n",
    "# Import nn.functional\n",
    "import torch.nn.functional as F\n",
    "loss_fn = F.mse_loss\n",
    "\n",
    "loss = loss_fn(model(inputs), targets)\n",
    "print(loss)\n",
    "\n",
    "# Define optimizer\n",
    "opt = torch.optim.SGD(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "\n",
    "# Utility function to train the model\n",
    "def fit(num_epochs, model, loss_fn, opt, train_dl):\n",
    "    \n",
    "    # Repeat for given number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # Train with batches of data\n",
    "        for xb,yb in train_dl:\n",
    "            \n",
    "            # 1. Generate predictions\n",
    "            pred = model(xb)\n",
    "            \n",
    "            # 2. Calculate loss\n",
    "            loss = loss_fn(pred, yb)\n",
    "            \n",
    "            # 3. Compute gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # 4. Update parameters using gradients\n",
    "            opt.step()\n",
    "            \n",
    "            # 5. Reset the gradients to zero\n",
    "            opt.zero_grad()\n",
    "        \n",
    "        # Print the progress\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 537.2679\n",
      "Epoch [20/100], Loss: 147.8839\n",
      "Epoch [30/100], Loss: 128.2723\n",
      "Epoch [40/100], Loss: 89.1374\n",
      "Epoch [50/100], Loss: 49.0374\n",
      "Epoch [60/100], Loss: 21.5867\n",
      "Epoch [70/100], Loss: 44.5280\n",
      "Epoch [80/100], Loss: 26.6871\n",
      "Epoch [90/100], Loss: 32.7600\n",
      "Epoch [100/100], Loss: 18.7048\n"
     ]
    }
   ],
   "source": [
    "fit(100, model, loss_fn, opt, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 57.8430,  71.2984],\n",
      "        [ 82.7410,  97.7221],\n",
      "        [114.7756, 136.7427],\n",
      "        [ 25.8661,  43.1475],\n",
      "        [100.2645, 110.5900],\n",
      "        [ 56.7555,  70.2703],\n",
      "        [ 82.6872,  97.2947],\n",
      "        [115.1543, 137.0840],\n",
      "        [ 26.9537,  44.1757],\n",
      "        [101.2983, 111.1907],\n",
      "        [ 57.7893,  70.8710],\n",
      "        [ 81.6534,  96.6940],\n",
      "        [114.8293, 137.1701],\n",
      "        [ 24.8323,  42.5468],\n",
      "        [101.3521, 111.6181]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.],\n",
      "        [ 57.,  69.],\n",
      "        [ 80., 102.],\n",
      "        [118., 132.],\n",
      "        [ 21.,  38.],\n",
      "        [104., 118.],\n",
      "        [ 57.,  69.],\n",
      "        [ 82., 100.],\n",
      "        [118., 134.],\n",
      "        [ 20.,  38.],\n",
      "        [102., 120.]])\n"
     ]
    }
   ],
   "source": [
    "print(model(inputs))\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[54.8541, 67.9163]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction for a specific case\n",
    "model(torch.tensor([[75, 63, 44.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 9820.2803\n",
      "Epoch [20/100], Loss: 3121.2239\n",
      "Epoch [30/100], Loss: 2126.2554\n",
      "Epoch [40/100], Loss: 2384.7454\n",
      "Epoch [50/100], Loss: 2420.4482\n",
      "Epoch [60/100], Loss: 4236.0117\n",
      "Epoch [70/100], Loss: 3013.8711\n",
      "Epoch [80/100], Loss: 1944.3519\n",
      "Epoch [90/100], Loss: 1295.6188\n",
      "Epoch [100/100], Loss: 2064.5112\n"
     ]
    }
   ],
   "source": [
    "# NN modeling\n",
    "\n",
    "model2 = nn.Sequential(\n",
    "    nn.Linear(3, 4), # hidden layer\n",
    "    nn.Sigmoid(),    # non-linearity, activation function\n",
    "    nn.Linear(4, 2)  # output layer\n",
    ")\n",
    "\n",
    "opt = torch.optim.SGD(model2.parameters(), lr=1e-3)\n",
    "\n",
    "fit(100, model2, F.mse_loss, opt, train_dl)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d46af94c2bbce495f1e668725902fa517c90b1782bcfe2fce0dd9868df553d3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
