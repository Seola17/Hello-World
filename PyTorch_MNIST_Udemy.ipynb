{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(0.5, 0.5)])\n",
    "train_dataset = datasets.MNIST(root='/data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='/data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.drop = nn.Dropout(p=0.9)\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)         # (28x28) -> (24x24)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)        # (24x24) -> (20x20)\n",
    "        self.fc2 = nn.Linear(16*20*20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.drop(self.conv1(x)))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.fc2(x.view(-1, 16*20*20))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-5, betas=(0.99, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1/10, \t loss: 0.274\n",
      "epoch:  2/10, \t loss: 0.102\n",
      "epoch:  3/10, \t loss: 0.110\n",
      "epoch:  4/10, \t loss: 0.108\n",
      "epoch:  5/10, \t loss: 0.178\n",
      "epoch:  6/10, \t loss: 0.157\n",
      "epoch:  7/10, \t loss: 0.157\n",
      "epoch:  8/10, \t loss: 0.274\n",
      "epoch:  9/10, \t loss: 0.115\n",
      "epoch: 10/10, \t loss: 0.195\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    for _, samples in enumerate(train_loader):\n",
    "        images, labels = samples\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        output = net(images)\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('epoch: {:2d}/{}, \\t loss: {:.3f}'.format(epoch+1, epochs, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 94.772%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for _, samples in enumerate(test_loader):\n",
    "    images, labels = samples\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    output = net(images)\n",
    "    predictions = output.argmax(dim=1)\n",
    "\n",
    "    correct += (predictions == labels).sum()\n",
    "    total += labels.shape[0]\n",
    "\n",
    "print(f'accuracy: {correct / total * 100:.3f}%')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Resnet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Resnet, self).__init__()\n",
    "        # first layer\n",
    "        self.fc1 = nn.Linear(1*28*28, 1*28*28)\n",
    "        # residual layer\n",
    "        self.conv1 = nn.Conv2d(1, 1, 5, padding=2)\n",
    "        # last layer\n",
    "        self.fc2 = nn.Linear(1*28*28, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_shape = x.shape\n",
    "        x = F.relu(self.fc1(x.view(-1, 1*28*28))).view(x_shape)\n",
    "\n",
    "        # resnet block\n",
    "        x = F.relu(self.conv1(x)) + x\n",
    "\n",
    "        x = self.fc2(x.view(-1, 1*28*28))       # vectorizing x to forward to the linear layer\n",
    "        return x\n",
    "\n",
    "net = Resnet().to(device)\n",
    "t = torch.randn((64, 1, 28, 28)).to(device)\n",
    "net(t).shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d46af94c2bbce495f1e668725902fa517c90b1782bcfe2fce0dd9868df553d3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
